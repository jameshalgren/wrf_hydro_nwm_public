{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic imports\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "## Parallel execution\n",
    "import multiprocessing\n",
    "\n",
    "# WARNING: These global declarations cause the parallel implementation to \n",
    "# crash when executed on Windows\n",
    "connections = None\n",
    "networks = None\n",
    "flowdepthvel = None\n",
    "num_processes = None\n",
    "\n",
    "from sys import platform\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    pass\n",
    "elif platform == \"darwin\":\n",
    "    pass\n",
    "elif platform == \"win32\":\n",
    "    print('The parallel version of compute_nhd_routing.py will not execute as currently')\n",
    "    print('written due to the lack of a fork() capability in the windows OS.')\n",
    "    print('For parallel execution, please us a *nix OS.')\n",
    "    print('\\nexiting...')\n",
    "    sys.exit()\n",
    "    # Some useful references:\n",
    "    # https://stackoverflow.com/questions/985281/what-is-the-closest-thing-windows-has-to-fork/985525#985525\n",
    "    # https://stackoverflow.com/questions/8220108/how-do-i-check-the-operating-system-in-python\n",
    "    # https://stackoverflow.com/questions/6596617/python-multiprocess-diff-between-windows-and-linux\n",
    "\n",
    "ENV_IS_CL = False\n",
    "if ENV_IS_CL: root = '/content/wrf_hydro_nwm_public/trunk/NDHMS/dynamic_channel_routing/'\n",
    "elif not ENV_IS_CL: \n",
    "    sys.setrecursionlimit(4000)\n",
    "    root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "    sys.path.append(os.path.join(root, r'src', r'python_framework'))\n",
    "    fortran_source_dir = os.path.join(root, r'src', r'fortran_routing', r'mc_pylink_v00', r'MC_singleCH_singleTS')\n",
    "    sys.path.append(fortran_source_dir)\n",
    "    try:\n",
    "        import mc_sc_stime as mc\n",
    "    except:\n",
    "        import subprocess\n",
    "        fortran_compile_call = []\n",
    "        fortran_compile_call.append(r'f2py3')\n",
    "        fortran_compile_call.append(r'-c')\n",
    "        fortran_compile_call.append(r'varSingleChStime_f2py.f90')\n",
    "        fortran_compile_call.append(r'MCsingleChStime_f2py_clean.f90')\n",
    "        fortran_compile_call.append(r'-m')\n",
    "        fortran_compile_call.append(r'mc_sc_stime')\n",
    "        subprocess.run(fortran_compile_call, cwd=fortran_source_dir, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        try:\n",
    "            import mc_sc_stime as mc\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "\n",
    "## network and reach utilities\n",
    "import nhd_network_utilities as nnu\n",
    "import nhd_reach_utilities as nru\n",
    "\n",
    "## Muskingum Cunge\n",
    "import numpy as np\n",
    "\n",
    "def compute_network(\n",
    "        terminal_segment = None\n",
    "        , network = None\n",
    "        , supernetwork_data = None\n",
    "        # , connections = None\n",
    "        , verbose = False\n",
    "        , debuglevel = 0\n",
    "        ):\n",
    "\n",
    "    global connections\n",
    "    global flowdepthvel \n",
    "\n",
    "    if verbose: print(f\"\\nExecuting simulation on network {terminal_segment} beginning with streams of order {network['maximum_reach_seqorder']}\")\n",
    "\n",
    "    ordered_reaches = {}\n",
    "    for head_segment, reach in network['reaches'].items():\n",
    "        if reach['seqorder'] not in ordered_reaches:\n",
    "            ordered_reaches.update({reach['seqorder']:[]}) #TODO: Should this be a set/dictionary?\n",
    "        ordered_reaches[reach['seqorder']].append([head_segment\n",
    "                  , reach\n",
    "                  ])\n",
    "    for x in range(network['maximum_reach_seqorder'],-1,-1):\n",
    "        for head_segment, reach in ordered_reaches[x]:\n",
    "            compute_reach_up2down(\n",
    "                head_segment = head_segment\n",
    "                , reach = reach\n",
    "                # , connections = connections\n",
    "                , supernetwork_data = supernetwork_data\n",
    "                , verbose = verbose\n",
    "                , debuglevel = debuglevel\n",
    "                )\n",
    "\n",
    "def compute_network_parallel(\n",
    "        large_networks = None\n",
    "        , supernetwork_data = None\n",
    "        # , connections = None\n",
    "        , verbose = False\n",
    "        , debuglevel = 0\n",
    "        ):\n",
    "\n",
    "    global connections\n",
    "    global flowdepthvel \n",
    "    global num_processes\n",
    "\n",
    "    overall_max = -1\n",
    "    for terminal_segment, network in large_networks.items():\n",
    "        overall_max = max(network['maximum_reach_seqorder'], overall_max)\n",
    "\n",
    "    if verbose: print(f\"Executing simulation for all large network beginning with maximum order {overall_max}\")\n",
    "\n",
    "    nts = 216 # number fof timestep\n",
    "    \n",
    "    #if 1 == 1:\n",
    "    ordered_reaches = {}\n",
    "    ordered_reaches.update({overall_max:[]})\n",
    "    #import pdb; pdb.set_trace()\n",
    "    for terminal_segment, network in large_networks.items():\n",
    "        for head_segment, reach in network['reaches'].items():\n",
    "            if reach['seqorder'] not in ordered_reaches:\n",
    "                ordered_reaches.update({reach['seqorder']:[]}) #TODO: Should this be a set/dictionary?\n",
    "            if reach['upstream_reaches'] == {supernetwork_data['terminal_code']}:\n",
    "                print('headwater')\n",
    "                ordered_reaches[overall_max].append([head_segment\n",
    "                          , reach\n",
    "                          , supernetwork_data\n",
    "                          , verbose\n",
    "                          , debuglevel])\n",
    "            else:\n",
    "                ordered_reaches[reach['seqorder']].append([head_segment\n",
    "                          , reach\n",
    "                          , supernetwork_data\n",
    "                          , verbose\n",
    "                          , debuglevel])\n",
    "            #import pdb; pdb.set_trace()\n",
    "            #print(ordered_reaches)\n",
    "    \n",
    "    with multiprocessing.Pool() as netpool:\n",
    "\n",
    "        num_processes = netpool._processes\n",
    "        for ts in range (0,nts):\n",
    "            #print(f'timestep: {ts}\\n')\n",
    "\n",
    "            for x in range(overall_max,-1,-1):\n",
    "                nslist3 = ordered_reaches[x]\n",
    "                #print(f'Time: {ts} Execution Args for order {x}: {nslist3}')\n",
    "                if verbose: print(f\"Time: {ts} Executing simulation for {len(nslist3)} large network reaches of order {x}\")\n",
    "                results = netpool.starmap(compute_mc_reach_up2down, nslist3)\n",
    "\n",
    "\n",
    "# ### Psuedocode\n",
    "# \n",
    "# ```\n",
    "# Call Compute Network\n",
    "#     for each reach in the network\n",
    "#         Call compute reach\n",
    "#             For each segment in the reach\n",
    "#                 Import the mc object/module\n",
    "#                 Call prepare segment\n",
    "#                     Populate the Mc segment array with the individual segment properties\n",
    "#                     Obtain and set any lateral inflows\n",
    "#                     obtain and set the upstream and downstream (requrires logic to deal with junctions or boundaries at headwaters)\n",
    "#                 With the populated arrays, execute MC for the reach\n",
    "# ```     \n",
    "#         \n",
    "\n",
    "def read_segments():\n",
    "    pass\n",
    "\n",
    "def prepare_segments():\n",
    "    pass\n",
    "\n",
    "def handle_junctions():\n",
    "    pass\n",
    "\n",
    "def get_upstream_inflow():\n",
    "    pass\n",
    "\n",
    "def get_lateral_inflow():\n",
    "    pass\n",
    "\n",
    "def compute_junction_downstream():\n",
    "    pass\n",
    "\n",
    "#TODO: generalize with a direction flag\n",
    "def compute_mc_reach_up2down(\n",
    "        head_segment = None\n",
    "        , reach = None\n",
    "        #, connections = None\n",
    "        , supernetwork_data = None\n",
    "        , ts = 0\n",
    "        , verbose = False\n",
    "        , debuglevel = 0\n",
    "        ):\n",
    "    \n",
    "    global connections\n",
    "    global flowdepthvel\n",
    "    # global network\n",
    "    \n",
    "    if verbose: print(f\"\\nreach: {head_segment} (order: {reach['seqorder']} n_segs: {len(reach['segments'])})\")\n",
    "    \n",
    "    ntim=2;       #the number of time steps necessary for variables passed to mc module to compute successfully\n",
    "    nlinks=2;     #the number of links needed to define varialbe qd. ** nlinks is not used in fortran source code.\n",
    "\n",
    "    mc.var.uslinkid=1\n",
    "    mc.var.linkid=2\n",
    "    ncomp0=1; mc.var.ncomp0=ncomp0  #the number of segments of a reach upstream of the current reach\n",
    "    ncomp = len(reach['segments']) ;  mc.var.ncomp= ncomp  #the number of segments of the current reach \n",
    "    #mxseg=max(ncomp0,ncomp)    \n",
    "    #MC model outputs\n",
    "    mc.var.qd=np.zeros((ntim,ncomp,nlinks))  #will store MC output qdc (flow downstream current timestep) \n",
    "    mc.var.vela=np.zeros((ntim,ncomp)) \n",
    "    mc.var.deptha=np.zeros((ntim,ncomp))\n",
    "    #lateral flow\n",
    "    mc.var.qlat=np.zeros((ncomp))\n",
    "     \n",
    "    \n",
    "    \n",
    "    # upstream flow per reach\n",
    "    qup_tmp = 0\n",
    "    #import pdb; pdb.set_trace()\n",
    "    if reach['upstream_reaches'] == {supernetwork_data['terminal_code']}: # Headwaters\n",
    "        qup_tmp = (ts+1)*10.0 \n",
    "    else: # Loop over upstream reaches\n",
    "        #for us in reach['upstream_reaches']:\n",
    "        for us in connections[reach['reach_head']]['upstreams']:\n",
    "            #if us == 5507050 :\n",
    "            #    import pdb; pdb.set_trace()\n",
    "            #qup_tmp += flowdepthvel[network['reaches'][us]['reach_tail']]['flow']['curr']\n",
    "            qup_tmp += flowdepthvel[us]['flow']['curr']\n",
    "    \n",
    "    flowdepthvel[reach['reach_head']]['flow']['curr'] = qup_tmp\n",
    "    #print(qup_tmp)\n",
    "            \n",
    "    current_segment = reach['reach_head']\n",
    "    next_segment = connections[current_segment]['downstream'] \n",
    "    #print(f'{current_segment}==>{next_segment} conections:{ncomp} timestep:{ts}')\n",
    "    i = 0\n",
    "    #input flow to upstream reach of current reach   \n",
    "    mc.var.qd[1,i,0] = qup_tmp \n",
    "    \n",
    "    while True:\n",
    "\n",
    "        # for now treating as constant per reach \n",
    "        dt=300.0 ;      mc.var.dt= dt  #60.0;\n",
    "\n",
    "        dx=connections[current_segment]['data'][supernetwork_data['length_col']] ;     mc.var.dx= dx  #20.0\n",
    "        bw=connections[current_segment]['data'][supernetwork_data['bottomwidth_col']];       mc.var.bw= bw #50\n",
    "        tw= 0.01*bw; mc.var.tw= tw\n",
    "        twcc=tw;     mc.var.twcc=twcc\n",
    "        n=connections[current_segment]['data'][supernetwork_data['manningn_col']] ;      mc.var.n=n #0.03\n",
    "        ncc=n;       mc.var.ncc=ncc\n",
    "        cs=connections[current_segment]['data'][supernetwork_data['ChSlp_col']] ;    mc.var.cs=cs #1.0e6\n",
    "        so=connections[current_segment]['data'][supernetwork_data['slope_col']];    mc.var.so=so #0.002\n",
    "        #ck= current_segment['data'][supernetwork['MusK_col']];   mc.var.ck = ck \n",
    "        #cx= current_segment['data'][supernetwork['MusX_col']];   mc.var.cx = cx\n",
    "        #print (f'{current_segment}')\n",
    "               \n",
    "        flowdepthvel[current_segment]['qlat']['curr'] = (ts+1)*2.0      # lateral flow per segment\n",
    "       \n",
    "                      \n",
    "        flowdepthvel[current_segment]['flow']['prev'] = flowdepthvel[current_segment]['flow']['curr']\n",
    "        flowdepthvel[current_segment]['depth']['prev'] = flowdepthvel[current_segment]['depth']['curr']\n",
    "        flowdepthvel[current_segment]['vel']['prev'] = flowdepthvel[current_segment]['vel']['curr']\n",
    "        flowdepthvel[current_segment]['qlat']['prev'] = flowdepthvel[current_segment]['qlat']['curr']\n",
    "\n",
    "        #print (f'counter = {i}')\n",
    "        #if current_segment == 5559368 or i == 100:\n",
    "        #    import pdb; pdb.set_trace()\n",
    "\n",
    "        mc.var.qlat[i]= flowdepthvel[current_segment]['qlat']['curr']  # temporary assigned qlat \n",
    "        mc.var.qd[0,i,1]= flowdepthvel[current_segment]['flow']['prev']  # temporary assigned qd\n",
    "        mc.var.vela[0,i] = flowdepthvel[current_segment]['vel']['prev']\n",
    "        mc.var.deptha[0,i] = flowdepthvel[current_segment]['depth']['prev']\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if current_segment == reach['reach_tail']:\n",
    "            if verbose: print(f'{current_segment} (tail)')\n",
    "            break\n",
    "        if verbose: print(f'{current_segment} --> {next_segment}\\n')\n",
    "        current_segment = next_segment\n",
    "        next_segment = connections[current_segment]['downstream'] \n",
    "        \n",
    "    mc.mc.main()\n",
    "\n",
    "    #print (f'{ts} end mc')\n",
    "    \n",
    "    current_segment = reach['reach_head']\n",
    "    next_segment = connections[current_segment]['downstream'] \n",
    "    i = 0\n",
    "    while True:\n",
    "        flowdepthvel[current_segment]['flow']['curr'] = mc.var.qd[1,i,1] \n",
    "        flowdepthvel[current_segment]['depth']['curr'] = mc.var.deptha[1,i]\n",
    "        flowdepthvel[current_segment]['vel']['curr'] = mc.var.vela[1,i]\n",
    "        d = flowdepthvel[current_segment]['depth']['curr'] \n",
    "        q = flowdepthvel[current_segment]['flow']['curr']\n",
    "        v = flowdepthvel[current_segment]['vel']['curr']\n",
    "        ql = flowdepthvel[current_segment]['qlat']['curr']\n",
    "        #print ( f'timestep: {ts} cur : {current_segment}  {q} {d} {v} {ql}')\n",
    "        i += 1\n",
    "        \n",
    "        #print(f'timestep: {ts} {flowdepthvel[current_segment]}')\n",
    "        #import pdb; pdb.set_trace()\n",
    "        \n",
    "            \n",
    "        if current_segment == reach['reach_tail']:\n",
    "            if verbose: print(f'{current_segment} (tail)')\n",
    "            break\n",
    "        if verbose: print(f'{current_segment} --> {next_segment}\\n')\n",
    "        current_segment = next_segment\n",
    "        next_segment = connections[current_segment]['downstream'] \n",
    "\n",
    "def main():\n",
    "\n",
    "    global connections\n",
    "    global networks\n",
    "    global flowdepthvel\n",
    "\n",
    "    verbose = True\n",
    "    debuglevel = 0\n",
    "    showtiming = True\n",
    "\n",
    "    test_folder = os.path.join(root, r'test')\n",
    "    geo_input_folder = os.path.join(test_folder, r'input', r'geo', r'Channels')\n",
    "\n",
    "    #TODO: Make these commandline args\n",
    "    \"\"\"##NHD Subset (Brazos/Lower Colorado)\"\"\"\n",
    "    supernetwork = 'Brazos_LowerColorado_ge5'\n",
    "    \"\"\"##NHD CONUS order 5 and greater\"\"\"\n",
    "    # supernetwork = 'CONUS_ge5'\n",
    "    \"\"\"These are large -- be careful\"\"\"\n",
    "    # supernetwork = 'Mainstems_CONUS'\n",
    "    # supernetwork = 'CONUS_FULL_RES_v20'\n",
    "    # supernetwork = 'CONUS_Named_Streams' #create a subset of the full resolution by reading the GNIS field\n",
    "    # supernetwork = 'CONUS_Named_combined' #process the Named streams through the Full-Res paths to join the many hanging reaches\n",
    "\n",
    "\n",
    "    if verbose: print('creating supernetwork connections set')\n",
    "    if showtiming: start_time = time.time()\n",
    "    #STEP 1\n",
    "    supernetwork_data, supernetwork_values = nnu.set_networks(\n",
    "        supernetwork = supernetwork\n",
    "        , geo_input_folder = geo_input_folder\n",
    "        , verbose = False\n",
    "        # , verbose = verbose\n",
    "        , debuglevel = debuglevel\n",
    "        )\n",
    "    if verbose: print('supernetwork connections set complete')\n",
    "    if showtiming: print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "    #STEP 2\n",
    "    if showtiming: start_time = time.time()\n",
    "    if verbose: print('organizing connections into networks and reaches ...')\n",
    "    networks = nru.compose_reaches(\n",
    "        supernetwork_values\n",
    "        , verbose = False\n",
    "        # , verbose = verbose\n",
    "        , debuglevel = debuglevel\n",
    "        , showtiming = showtiming\n",
    "        )\n",
    "    if verbose: print('reach organization complete')\n",
    "    if showtiming: print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "    #STEP 3\n",
    "    connections = supernetwork_values[0]\n",
    "    #initialize flowdepthvel dict\n",
    "    flowdepthvel = {connection:{'flow':{'prev':0, 'curr':0}\n",
    "                                , 'depth':{'prev':-999, 'curr':0}\n",
    "                                , 'vel':{'prev':0, 'curr':0}\n",
    "                                , 'qlat':{'prev':0, 'curr':0}} for connection in connections} \n",
    "    parallel_split = -1 # -1 turns off the splitting and runs everything through the lumped execution\n",
    "\n",
    "    #STEP 3a -- Large Networks\n",
    "    if showtiming: start_time = time.time()\n",
    "    if verbose: print(f'executing computation on ordered reaches for networks of order greater than {parallel_split} ...')\n",
    "\n",
    "    large_networks = {terminal_segment: network \\\n",
    "                      for terminal_segment, network in networks.items() \\\n",
    "                      if network['maximum_reach_seqorder'] > parallel_split}\n",
    "    # print(large_networks)\n",
    "    compute_network_parallel(\n",
    "        large_networks\n",
    "        , supernetwork_data = supernetwork_data\n",
    "        # , connections = connections\n",
    "        # , verbose = False\n",
    "        , verbose = verbose\n",
    "        , debuglevel = debuglevel\n",
    "    )\n",
    "    if verbose: print(f'ordered reach computation complete for networks of order greater than {parallel_split}')\n",
    "    if showtiming: print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    if showtiming: print(f'... with {num_processes} cores')\n",
    "\n",
    "    ##STEP 3b -- Small Networks\n",
    "    if parallel_split >= 0: print(r'DO NOT RUN WITH `parallel_split` >= 0')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
