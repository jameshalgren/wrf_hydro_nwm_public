{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic imports\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pixiedust\n",
    "\n",
    "# WARNING: These global declarations cause the parallel implementation to \n",
    "# crash when executed on Windows\n",
    "connections = None\n",
    "networks = None\n",
    "flowdepthvel = None\n",
    "\n",
    "from sys import platform\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    pass\n",
    "elif platform == \"darwin\":\n",
    "    pass\n",
    "elif platform == \"win32\":\n",
    "    print('The parallel version of compute_nhd_routing.py will not execute as currently')\n",
    "    print('written due to the lack of a fork() capability in the windows OS.')\n",
    "    print('For parallel execution, please us a *nix OS.')\n",
    "    print('\\nexiting...')\n",
    "    sys.exit()\n",
    "    # Some useful references:\n",
    "    # https://stackoverflow.com/questions/985281/what-is-the-closest-thing-windows-has-to-fork/985525#985525\n",
    "    # https://stackoverflow.com/questions/8220108/how-do-i-check-the-operating-system-in-python\n",
    "    # https://stackoverflow.com/questions/6596617/python-multiprocess-diff-between-windows-and-linux\n",
    "\n",
    "ENV_IS_CL = False\n",
    "if ENV_IS_CL: root = '/content/wrf_hydro_nwm_public/trunk/NDHMS/dynamic_channel_routing/'\n",
    "elif not ENV_IS_CL: \n",
    "    sys.setrecursionlimit(4000)\n",
    "#     root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "    root = os.path.dirname(os.path.dirname(os.path.abspath('')))    \n",
    "    sys.path.append(os.path.join(root, r'src', r'python_framework'))\n",
    "    fortran_source_dir = os.path.join(root, r'src', r'fortran_routing', r'mc_pylink_v00', r'MC_singleRCH_singleTS')\n",
    "    sys.path.append(fortran_source_dir)\n",
    "    from mc_singleCh_SingleTStep import compute_mc_reach_up2down\n",
    "    # import mc_sc_stime as mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pixie_debugger\n",
    "## network and reach utilities\n",
    "import nhd_network_utilities as nnu\n",
    "import nhd_reach_utilities as nru\n",
    "\n",
    "## Muskingum Cunge\n",
    "import numpy as np\n",
    "\n",
    "def compute_network(\n",
    "        terminal_segment = None\n",
    "        , network = None\n",
    "        , supernetwork_data = None\n",
    "        , nts = None\n",
    "        # , connections = None\n",
    "        , verbose = False\n",
    "        , debuglevel = 0\n",
    "        ):\n",
    "\n",
    "    global connections\n",
    "    global flowdepthvel \n",
    "\n",
    "    if verbose: print(f\"Executing simulation on network {terminal_segment} beginning with streams of order {network['maximum_reach_seqorder']}\")\n",
    "\n",
    "    ordered_reaches = {}\n",
    "    reach_flowdepthvel = {}\n",
    "    for head_segment, reach in network['reaches'].items():\n",
    "        if reach['seqorder'] not in ordered_reaches:\n",
    "            ordered_reaches.update({reach['seqorder']:[]}) #TODO: Should this be a set/dictionary?\n",
    "        ordered_reaches[reach['seqorder']].append([head_segment\n",
    "                  , reach\n",
    "                  ])\n",
    "\n",
    "        #initialize flowdepthvel dict\n",
    "        reach_flowdepthvel.update({head_segment:{}})\n",
    "        reach_flowdepthvel[head_segment].update(\n",
    "            {seg:{'flow':{'prev':0, 'curr':0}\n",
    "                , 'depth':{'prev':-999, 'curr':0}\n",
    "                , 'vel':{'prev':0, 'curr':0}\n",
    "                , 'qlat':{'prev':0, 'curr':0}} for seg in reach['segments']} \n",
    "        )\n",
    "\n",
    "    for ts in range (0,nts):\n",
    "        #print(f'timestep: {ts}\\n')\n",
    "\n",
    "        for x in range(network['maximum_reach_seqorder'],-1,-1):\n",
    "            for head_segment, reach in ordered_reaches[x]:\n",
    "                #print(f'{{{head_segment}}}:{reach}')          \n",
    "\n",
    "                #TODO: Add a flag here to switch between methods\n",
    "                compute_method = 'byreach' # Other options: 'bysegment'\n",
    "                if compute_method == 'byreach':\n",
    "                    # upstream flow per reach\n",
    "                    qup_tmp = 0\n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    if reach['upstream_reaches'] == {supernetwork_data['terminal_code']}: # Headwaters\n",
    "                        qup_tmp = 0.0  # no flows\n",
    "                    else: # Loop over upstream reaches\n",
    "                        #for us in reach['upstream_reaches']:\n",
    "                        for us in reach['upstream_reaches']:\n",
    "                            #qup_tmp += flowdepthvel[network['reaches'][us]['reach_tail']]['flow']['curr']\n",
    "                            # import pdb; pdb.set_trace()\n",
    "                            qup_tmp += reach_flowdepthvel[us][network['reaches'][us]['reach_tail']]['flow']['curr']\n",
    "\n",
    "                    reach_connections = {key:connection for key, connection in connections.items() if key in reach['segments']}\n",
    "                    for current_segment in reach['segments']:\n",
    "                        # add some flow\n",
    "                        reach_flowdepthvel[head_segment][current_segment]['qlat']['curr'] = (ts+1)*10.0      # lateral flow per segment \n",
    "\n",
    "                        reach_flowdepthvel[head_segment][current_segment]['flow']['prev'] = reach_flowdepthvel[head_segment][current_segment]['flow']['curr']\n",
    "                        reach_flowdepthvel[head_segment][current_segment]['depth']['prev'] = reach_flowdepthvel[head_segment][current_segment]['depth']['curr']\n",
    "                        reach_flowdepthvel[head_segment][current_segment]['vel']['prev'] = reach_flowdepthvel[head_segment][current_segment]['vel']['curr']\n",
    "                        reach_flowdepthvel[head_segment][current_segment]['qlat']['prev'] = reach_flowdepthvel[head_segment][current_segment]['qlat']['curr']\n",
    "\n",
    "                    reach_flowdepthvel[head_segment].update(compute_mc_reach_up2down(\n",
    "                        head_segment = head_segment\n",
    "                        , reach = reach\n",
    "                        #, network = network\n",
    "                        , reach_connections = reach_connections\n",
    "                        , reach_flowdepthvel = reach_flowdepthvel[head_segment]\n",
    "                        , upstream_inflow = qup_tmp\n",
    "                        , supernetwork_data = supernetwork_data\n",
    "                        , ts = ts\n",
    "                        , verbose = verbose\n",
    "                        , debuglevel = debuglevel\n",
    "                    ))\n",
    "                    #print(f'timestep: {ts} {flowdepthvel}')          \n",
    "                    #print(f'{head_segment} {flowdepthvel[head_segment]}')          \n",
    "\n",
    "\n",
    "# ### Psuedocode\n",
    "# \n",
    "# ```\n",
    "# Call Compute Network\n",
    "#     for each reach in the network\n",
    "#         Call compute reach\n",
    "#             For each segment in the reach\n",
    "#                 Import the mc object/module\n",
    "#                 Call prepare segment\n",
    "#                     Populate the Mc segment array with the individual segment properties\n",
    "#                     Obtain and set any lateral inflows\n",
    "#                     obtain and set the upstream and downstream (requrires logic to deal with junctions or boundaries at headwaters)\n",
    "#                 With the populated arrays, execute MC for the reach\n",
    "# ```     \n",
    "#         \n",
    "\n",
    "def read_segments():\n",
    "    pass\n",
    "\n",
    "def prepare_segments():\n",
    "    pass\n",
    "\n",
    "def handle_junctions():\n",
    "    pass\n",
    "\n",
    "def get_upstream_inflow():\n",
    "    pass\n",
    "\n",
    "def get_lateral_inflow():\n",
    "    pass\n",
    "\n",
    "def compute_junction_downstream():\n",
    "    pass\n",
    "\n",
    "def main():\n",
    "\n",
    "    global connections\n",
    "    global networks\n",
    "    global flowdepthvel\n",
    "\n",
    "    verbose = True\n",
    "    debuglevel = 0\n",
    "    showtiming = True\n",
    "\n",
    "    test_folder = os.path.join(root, r'test')\n",
    "    geo_input_folder = os.path.join(test_folder, r'input', r'geo', r'Channels')\n",
    "\n",
    "    #TODO: Make these commandline args\n",
    "    \"\"\"##NHD Subset (Brazos/Lower Colorado)\"\"\"\n",
    "    supernetwork = 'Brazos_LowerColorado_ge5'\n",
    "    \"\"\"##NHD CONUS order 5 and greater\"\"\"\n",
    "    # supernetwork = 'CONUS_ge5'\n",
    "    \"\"\"These are large -- be careful\"\"\"\n",
    "    # supernetwork = 'Mainstems_CONUS'\n",
    "    # supernetwork = 'CONUS_FULL_RES_v20'\n",
    "    # supernetwork = 'CONUS_Named_Streams' #create a subset of the full resolution by reading the GNIS field\n",
    "    # supernetwork = 'CONUS_Named_combined' #process the Named streams through the Full-Res paths to join the many hanging reaches\n",
    "\n",
    "    if verbose: print('creating supernetwork connections set')\n",
    "    if showtiming: start_time = time.time()\n",
    "    #STEP 1\n",
    "    supernetwork_data, supernetwork_values = nnu.set_networks(\n",
    "        supernetwork = supernetwork\n",
    "        , geo_input_folder = geo_input_folder\n",
    "        , verbose = False\n",
    "        # , verbose = verbose\n",
    "        , debuglevel = debuglevel\n",
    "        )\n",
    "    if verbose: print('supernetwork connections set complete')\n",
    "    if showtiming: print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "    #STEP 2\n",
    "    if showtiming: start_time = time.time()\n",
    "    if verbose: print('organizing connections into networks and reaches ...')\n",
    "    networks = nru.compose_reaches(\n",
    "        supernetwork_values\n",
    "        , verbose = False\n",
    "        # , verbose = verbose\n",
    "        , debuglevel = debuglevel\n",
    "        , showtiming = showtiming\n",
    "        )\n",
    "    if verbose: print('reach organization complete')\n",
    "    if showtiming: print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "    #STEP 3\n",
    "    if showtiming: start_time = time.time()\n",
    "    executiontype = 'serial' # 'parallel'\n",
    "\n",
    "    if verbose: print('executing serial computation on ordered reaches ...')\n",
    "    connections = supernetwork_values[0]\n",
    "\n",
    "    number_of_time_steps = 50 # one timestep\n",
    "    #nts = 1440 # number fof timestep = 1140 * 60(model timestep) = 86400 = day\n",
    "    \n",
    "    #initialize flowdepthvel dict\n",
    "    flowdepthvel = {connection:{'flow':np.zeros(number_of_time_steps + 1)\n",
    "                                , 'depth':np.zeros(number_of_time_steps + 1)\n",
    "                                , 'vel':np.zeros(number_of_time_steps + 1)\n",
    "                                , 'qlat':np.zeros(number_of_time_steps + 1)}\n",
    "                       for connection in connections\n",
    "                   } \n",
    "\n",
    "    # from itertools import islice\n",
    "    # def take(iterable, n):\n",
    "    #     return list(islice(iterable, n))\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    if executiontype == 'serial':\n",
    "\n",
    "        for terminal_segment, network in networks.items():\n",
    "            if showtiming: network_start_time = time.time()\n",
    "            compute_network(\n",
    "                terminal_segment = terminal_segment\n",
    "                , network = network\n",
    "                , supernetwork_data = supernetwork_data\n",
    "                , nts = number_of_time_steps\n",
    "                # , connections = connections\n",
    "                , verbose = False\n",
    "                # , verbose = verbose\n",
    "                , debuglevel = debuglevel\n",
    "            )\n",
    "\n",
    "            if verbose: print(f'{terminal_segment} completed')\n",
    "            if showtiming: print(\"... in %s seconds.\" % (time.time() - network_start_time))\n",
    "        \n",
    "    if verbose: print('ordered reach computation complete')\n",
    "    if showtiming: print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
