{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read JSON data into input and output data (xall,yall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7222177\n",
      "7222177\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open('/home/jacob.hreha/nwm/trunk/NDHMS/dynamic_channel_routing/notebooks/table_size_26.json') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "with open('/home/jacob.hreha/nwm/trunk/NDHMS/dynamic_channel_routing/notebooks/table_size_51.json') as g:\n",
    "    data2 = json.load(g)\n",
    "\n",
    "xall = []\n",
    "yall =  []\n",
    "for x,y in data.items():\n",
    "        for z,c in y.items():\n",
    "            for f,g in c.items():\n",
    "                for t,u in g.items():\n",
    "                        array=[]\n",
    "                        array.append((float(x)))\n",
    "                        array.append((float(z)))\n",
    "                        array.append((float(f)))\n",
    "                        array.append((float(t)))\n",
    "                        yall.append([(float(u))])\n",
    "                        xall.append(array)\n",
    "                   \n",
    "                        \n",
    "for x,y in data2.items():\n",
    "        for z,c in y.items():\n",
    "            for f,g in c.items():\n",
    "                for t,u in g.items():\n",
    "                        array=[]\n",
    "                        array.append((float(x)))\n",
    "                        array.append((float(z)))\n",
    "                        array.append((float(f)))\n",
    "                        array.append((float(t)))\n",
    "                        yall.append([(float(u))])\n",
    "                        xall.append(array)\n",
    "                    \n",
    "\n",
    "print(len(xall))\n",
    "print(len(yall))    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxtrain = np.array(xall[:6000000])\n",
    "yytrain = np.array(yall[:6000000])\n",
    "xxtest = np.array(xall[6000000:])\n",
    "yytest = np.array(yall[6000000:]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000000, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(64, activation=tf.nn.relu, input_shape=[4]))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation=tf.nn.relu))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide what to track "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mean_absolute_error', 'mean_squared_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Normalize input data to be between -1,1 \n",
    " - Necessary to improve accuracy as values don't range widely\n",
    " - Without normalization very large/small values will push or pull the networks predictions too heavily\n",
    " - Run model and select epoch number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7222177 samples\n",
      "5306496/7222177 [=====================>........] - ETA: 1:08 - loss: 3.3598e-04 - mean_absolute_error: 0.0087 - mean_squared_error: 3.3598e-04"
     ]
    }
   ],
   "source": [
    "d = xall\n",
    "\n",
    "\n",
    "\n",
    "min_d = np.min(d)\n",
    "max_d = np.max(d)\n",
    "normalized_d = (d - min_d) / (max_d - min_d)\n",
    "\n",
    "denormalized_d = normalized_d * (max_d - min_d) + min_d\n",
    "\n",
    "f = yall\n",
    "\n",
    "\n",
    "\n",
    "min_f = np.min(f)\n",
    "max_f = np.max(f)\n",
    "normalized_f = (f - min_f) / (max_f - min_f)\n",
    "\n",
    "denormalized_f = normalized_f * (max_f - min_f) + min_f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(normalized_d,normalized_f,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = xall\n",
    "\n",
    "\n",
    "\n",
    "min_d = np.min(d)\n",
    "max_d = np.max(d)\n",
    "normalized_d = (d - min_d) / (max_d - min_d)\n",
    "\n",
    "denormalized_d = normalized_d * (max_d - min_d) + min_d\n",
    "\n",
    "k = model.predict(normalized_d)\n",
    "# print(k)\n",
    "# denormalized_k = k * (max_d - min_d) + min_d\n",
    "# print(denormalized_k[6000000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(k[6000000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denormalized_f = k * (max_f - min_f) + min_f\n",
    "print(denormalized_f[6000000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non normalized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtrain[0])\n",
    "print(ytrain[0])\n",
    "print(xtest[0])\n",
    "print(ytest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.setdiff1d(denormalized_f[6000000:], yytest))\n",
    "t = (np.setdiff1d(denormalized_f[6000000:], yytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +- Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(t)/len(denormalized_f[6000000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "testsize = np.arange(4000000).reshape(1000000,4)\n",
    "testsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = testsize\n",
    "\n",
    "\n",
    "\n",
    "min_d = np.min(d)\n",
    "max_d = np.max(d)\n",
    "normalized_d = (d - min_d) / (max_d - min_d)\n",
    "\n",
    "denormalized_d = normalized_d * (max_d - min_d) + min_d\n",
    "\n",
    "k = model.predict(normalized_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
